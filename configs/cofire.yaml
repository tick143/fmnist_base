training:
  epochs: 5
  batch_size: 128
  log_interval: 100
  device: auto
  seed: 42
  num_workers: 4

dataset:
  root: ./data
  download: true

model:
  target: alt_back.models.mlp.FashionMLP
  params:
    hidden_layers: [512, 256]
    dropout: 0.2

backward:
  target: alt_back.backward.cofire.CoFireBackwardStrategy
  params:
    lr: 1.0
    clamp_value: 4.0
    clamp_penalty: 0.05
    entropy_weight: 1.0

optimizer:
  target: alt_back.optim.torch_optimizer.TorchOptimizerStrategy
  params:
    optimizer_class: torch.optim.SGD
    lr: 0.01

logging:
  enabled: true
  project: alt-back
  run_name: cofire-demo
  tags: ["cofire", "mlp"]
  log_logits: true
  log_probabilities: true
  log_entropies: true
