Metadata-Version: 2.4
Name: alt-back
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.2.0
Requires-Dist: torchvision>=0.17.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: wandb>=0.16
Requires-Dist: fastapi>=0.110
Requires-Dist: uvicorn>=0.24

## alt-back

Experimental playground for Fashion-MNIST with configurable "backwards" and optimisation strategies. The project is designed so you can swap out gradient calculation and weight update logic via configuration without touching the core training loop.

### Prerequisites

- Python 3.11+
- [uv](https://github.com/astral-sh/uv) for dependency and virtualenv management

### Getting started

```bash
uv venv
source .venv/bin/activate
uv sync
```

Then launch a default training run:

```bash
alt-back-train --config configs/default.yaml
```

To try the alternative co-firing rule with the MLP baseline and Weights & Biases logging:

```bash
alt-back-train --config configs/cofire.yaml
```

To experiment with the loss-free mass redistribution strategy that reallocates synaptic magnitude without backpropagation:

```bash
alt-back-train --config configs/mass_redistribution.yaml
```

### Tiny spiking playground

For a lightweight, synthetic demo that highlights how the mass-redistribution rule manipulates weights step-by-step, launch the interactive visualiser:

```bash
alt-back-viz --port 8000
```

This spins up a FastAPI server with a 5-10-2 spiking network trained on a balanced synthetic dataset (`y = 1` when `sum(x) > 2.5`). The web UI exposes single-step and auto-stepping controls, live topology visualisation, per-synapse deltas, spike-rate heatmaps, and running evaluation metrics.

### Configuration

All pluggable components are configured in YAML:

- `model.target`: dotted import path for the network module/class
- `backward.target`: class implementing `BackwardStrategy`
- `optimizer.target`: class implementing `OptimizerStrategy`

Each section is accompanied by `params` that are forwarded to the target class constructor. Define your own module under `src/alt_back/...` (or any importable package) and point the config at it to experiment with alternative update rules or biologically inspired models.

For gradient-free approaches, use `alt_back.optim.null_optimizer.NullOptimizerStrategy` so the backward rule can mutate parameters directly.

#### Logging

Enable Weights & Biases by setting `logging.enabled: true`. The trainer will stream batch metrics such as logits/probabilities statistics, prediction entropy, per-layer entropy, network-wide entropy, and any custom signals exposed by backward rules (e.g. clamp ratios in the co-fire strategy).

#### Extending strategies

Custom backwards/optimiser implementations receive a rich `BatchContext` object containing model, activations, targets, and metadata (epoch, batch index, device). Implementations can ignore unused fields while still having everything required for local or layer-wise learning rules.

### Next steps

- Implement custom `BackwardStrategy` classes to explore non-gradient or local learning rules
- Add additional optimiser strategies (e.g. Hebbian-style, equilibrium propagation)
- Extend the model zoo with modules that emulate growth or developmental processes
- Experiment with the provided `CoFireBackwardStrategy` that minimises layer entropy and encourages sequential neurons to co-activate
- Explore the `MassRedistributionBackwardStrategy` for backprop-free, magnitude-constrained plasticity dynamics
